{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alMayrink/PUC-Engenharia-Software/blob/main/C%C3%B3pia_de_13_ml_classificacao_poo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDnXLbAXQbBn"
      },
      "source": [
        "# Engenharia de Software para Ciência de Dados - PUC-Rio\n",
        "\n",
        "### Modelo de classificação simples usando POO\n",
        "\n",
        "Marcos Kalinowski e Tatiana Escovedo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeUm9vsF0nmY"
      },
      "outputs": [],
      "source": [
        "# Imports necessários\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris # para importar o dataset iris\n",
        "from sklearn.model_selection import train_test_split # para particionar em bases de treino e teste\n",
        "from sklearn.metrics import confusion_matrix # para a exibição da matriz de confusão do modelo\n",
        "from sklearn.metrics import accuracy_score # para a exibição da acurácia do modelo\n",
        "from sklearn.svm import SVC # para utilizar o algoritmo SVM\n",
        "from abc import ABC\n",
        "from abc import abstractmethod\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibELgG7qoQpP"
      },
      "source": [
        "## Sem POO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-870C7yUoQ0l",
        "outputId": "0d4cfd20-b99e-48c3-edd0-6dc367f7c675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8666666666666667\n"
          ]
        }
      ],
      "source": [
        "# Versão estruturada\n",
        "\n",
        "# Carga do dataset\n",
        "iris = load_iris()\n",
        "# conversão para dataframe\n",
        "dataset = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "dataset['target'] = iris.target  # adição da coluna target\n",
        "\n",
        "# Separação em bases de treino e teste\n",
        "array = dataset.values\n",
        "X = array[:, 0:4]\n",
        "Y = array[:, 4]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20,\n",
        "                                                    random_state=7)\n",
        "\n",
        "# Criação do modelo e predições\n",
        "model = SVC()  # cria o modelo\n",
        "model.fit(X_train, Y_train)  # treina o modelo com o dataset de treino\n",
        "predictions = model.predict(X_test)  # faz as predições com o dataset de teste\n",
        "\n",
        "# Avaliação das predições\n",
        "print(accuracy_score(Y_test, predictions))  # acurácia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5JdleHxMwdC"
      },
      "source": [
        "## Com POO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gudU2uP4PPL9",
        "outputId": "ddbb970c-0697-47ff-ea00-c17e1d32a2eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycodestyle\n",
            "  Downloading pycodestyle-2.9.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 341 kB/s \n",
            "\u001b[?25hCollecting pycodestyle_magic\n",
            "  Downloading pycodestyle_magic-0.5-py2.py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pycodestyle-magic, pycodestyle\n",
            "Successfully installed pycodestyle-2.9.1 pycodestyle-magic-0.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flake8\n",
            "  Downloading flake8-5.0.4-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 425 kB/s \n",
            "\u001b[?25hCollecting mccabe<0.8.0,>=0.7.0\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting importlib-metadata<4.3,>=1.1.0\n",
            "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pycodestyle<2.10.0,>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from flake8) (2.9.1)\n",
            "Collecting pyflakes<2.6.0,>=2.5.0\n",
            "  Downloading pyflakes-2.5.0-py2.py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3,>=1.1.0->flake8) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3,>=1.1.0->flake8) (3.10.0)\n",
            "Installing collected packages: pyflakes, mccabe, importlib-metadata, flake8\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.13.0\n",
            "    Uninstalling importlib-metadata-4.13.0:\n",
            "      Successfully uninstalled importlib-metadata-4.13.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.4.1 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\n",
            "gym 0.25.2 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\u001b[0m\n",
            "Successfully installed flake8-5.0.4 importlib-metadata-4.2.0 mccabe-0.7.0 pyflakes-2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pycodestyle pycodestyle_magic #não tem nada haver com SOLID.É para analisar o código\n",
        "!pip install flake8\n",
        "%load_ext pycodestyle_magic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHn8HbDg0i5P",
        "outputId": "8b801faf-fe62-4f3d-f90c-cecbc792a3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8666666666666667\n"
          ]
        }
      ],
      "source": [
        "%%pycodestyle #para analisar a qualidade do código\n",
        "\n",
        "# Em programas mais robustos, teríamos um arquivo .py para cada classe e\n",
        "# importaríamos as classes para executar o programa:\n",
        "# from <nome-do-arquivo> import <nome-da-classe>\n",
        "\n",
        "class Carregador:\n",
        "\n",
        "    def carregar_dados(self, url: str, atributos: list):\n",
        "        \"\"\" Carrega e retorna um DataFrame. Há diversos parâmetros \n",
        "        no read_csv que poderiam ser utilizados para dar opções \n",
        "        adicionais.\n",
        "        \"\"\"\n",
        "        return pd.read_csv(url, names=atributos)\n",
        "\n",
        "\n",
        "class PreProcessador:\n",
        "\n",
        "    def pre_processar(self, dataset, percentual_teste, seed=7):\n",
        "        \"\"\" Cuida de todo o pré-processamento. \"\"\"\n",
        "        # limpeza dos dados e eliminação de outliers\n",
        "\n",
        "        # feature selection\n",
        "\n",
        "        # divisão em treino e teste\n",
        "        X_train, X_test, Y_train, Y_test = self.__preparar_holdout(dataset,\n",
        "                                                                  percentual_teste,\n",
        "                                                                  seed)\n",
        "        # normalização/padronização\n",
        "        \n",
        "        return (X_train, X_test, Y_train, Y_test)\n",
        "\n",
        "    def __preparar_holdout(self, dataset, percentual_teste, seed):\n",
        "        \"\"\" Divide os dados em treino e teste usando o método holdout.\n",
        "        Assume que a variável target está na última coluna.\n",
        "        O parâmetro test_size é o percentual de dados de teste.\n",
        "        \"\"\"\n",
        "        dados = dataset.values\n",
        "        X = dados[:, 0:-1]\n",
        "        Y = dados[:, -1]\n",
        "        return train_test_split(X, Y, test_size=percentual_teste, random_state=seed)\n",
        "\n",
        "\n",
        "class Modelo:\n",
        "\n",
        "    def treinar_SVM(self, X_train, Y_train):\n",
        "        \"\"\" Cria e treina um modelo SVM. Poderia ter um Grid Search\n",
        "        com cross_validation para escolher os melhores hiperparâmetros, etc.\n",
        "        \"\"\"\n",
        "        modelo = SVC()\n",
        "        modelo.fit(X_train, Y_train)\n",
        "        return modelo\n",
        "\n",
        "\n",
        "class Avaliador:\n",
        "\n",
        "    def avaliar_acuracia(self, modelo, X_test, Y_test):\n",
        "        \"\"\" Faz uma predição e avalia o modelo. Poderia parametrizar o tipo de\n",
        "        avaliação, entre outros.\n",
        "        \"\"\"\n",
        "        predicoes = modelo.predict(X_test)\n",
        "        return accuracy_score(Y_test, predicoes)\n",
        "\n",
        "\n",
        "# Este código começaria daqui, logo após os imports\n",
        "# from loader import Loader #Se tivesse criado arquivos .py com o código\n",
        "# from preprocessor import PreProcessor\n",
        "# from ml_model import MLModel\n",
        "# from ml_evaluator import MlEvaluator # Nesse caso as classes estão escritas\n",
        "                                       # acima\"\"\"\n",
        "\n",
        "# Instanciação das Classes\n",
        "carregador = Carregador()\n",
        "pre_processador = PreProcessador()\n",
        "modelo = Modelo()\n",
        "avaliador = Avaliador()\n",
        "\n",
        "# Parâmetros\n",
        "url_dados = ('https://archive.ics.uci.edu/'\n",
        "             'ml/machine-learning-databases/iris/iris.data')\n",
        "atributos = ['comprimento_sepala', 'largura_sepala',\n",
        "             'comprimento_petala', 'largura_petala',\n",
        "             'especie']\n",
        "percentual_teste = 0.2\n",
        "\n",
        "# Código\n",
        "\n",
        "# Carga\n",
        "dataset = carregador.carregar_dados(url_dados, atributos)\n",
        "# Pré-processamento\n",
        "X_train, X_test, Y_train, Y_test = pre_processador.pre_processar(dataset, \n",
        "                                                               percentual_teste)\n",
        "# Treinamento do modelo\n",
        "model = modelo.treinar_SVM(X_train, Y_train)\n",
        "# Impressão do resultado da avaliação\n",
        "print(avaliador.avaliar_acuracia(model, X_test, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugzwgOZLlURp"
      },
      "source": [
        "## PyTest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6VHpme5dAlk"
      },
      "outputs": [],
      "source": [
        "!pip -q install pytest pytest-sugar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2dhM06seDSA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f6762dd-4528-448c-cb56-4f1d1ef459e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '*.py': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# cleanup all files\n",
        "%rm *.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmGr1Ln1ivgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c20de12-3ace-4ee8-d6e7-671211325b96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing loader.py\n"
          ]
        }
      ],
      "source": [
        "%%file loader.py #cria um arquivo com o codigo da classe Loader e grava no notebook\n",
        "\n",
        "# Imports necessários\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris # para importar o dataset iris\n",
        "\n",
        "class Loader:\n",
        "\n",
        "    def load_data(self, dataset_url: str, attributes: list):\n",
        "        \"\"\" Carrega e retorna um dataset.\n",
        "        Há diversos parâmetros no read_csv para dar opções adicionais.\n",
        "        \"\"\"\n",
        "        return pd.read_csv(dataset_url, names=attributes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXZEbC5zdQ5U",
        "outputId": "c9a31430-a804-4899-ffeb-de8e6bdf1334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_load.py\n"
          ]
        }
      ],
      "source": [
        "%%file test_load.py\n",
        "\n",
        "from loader import Loader\n",
        "\n",
        "def test_load_data():\n",
        "    url_dados = ('https://archive.ics.uci.edu/'\n",
        "                 'ml/machine-learning-databases/iris/iris.data')\n",
        "    atributos = ['comprimento_sepala', 'largura_sepala',\n",
        "                 'comprimento_petala', 'largura_petala',\n",
        "                 'especie']\n",
        "\n",
        "    loader = Loader()\n",
        "    dataset = loader.load_data(url_dados, atributos)\n",
        "    \n",
        "    assert len(dataset) == 150\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88Slw9_3dje5",
        "outputId": "1775f4bd-9004-4d0c-8d85-93db132a1c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mTest session starts (platform: linux, Python 3.7.15, pytest 3.6.4, pytest-sugar 0.9.6)\u001b[0m\n",
            "rootdir: /content, inifile:\n",
            "plugins: typeguard-2.7.1, sugar-0.9.6\n",
            "\n",
            " \u001b[36m\u001b[0mtest_load.py\u001b[0m \u001b[32m✓\u001b[0m                                                  \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█████████\u001b[0m\n",
            "\n",
            "Results (0.98s):\n",
            "\u001b[32m       1 passed\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python -m pytest test_load.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}