{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1BTORgj7Ul2pLMI1lU-BxbBOo_UqO7wXM","timestamp":1667941634208},{"file_id":"1j7gyCCGxHOeE24IlBSZ2mE-88F2pEKF_","timestamp":1637627819844}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"aUwCbt07o7UC"},"source":["# Engenharia de Software para Ciência de Dados - PUC-Rio\n","\n","### Pré-Processamento de Dados\n","Marcos Kalinowski e Tatiana Escovedo"]},{"cell_type":"markdown","metadata":{"id":"2-d_toBSBjPX"},"source":["**Referências:** https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing"]},{"cell_type":"code","metadata":{"id":"T1gTKd1qgRQg"},"source":["# configuração para não exibir os warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Importação de pacotes\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler # para normalização\n","from sklearn.preprocessing import StandardScaler # para padronização\n","from sklearn.preprocessing import OrdinalEncoder # para ordinal encoding\n","from sklearn.preprocessing import OneHotEncoder # para one-hot encoding e dummy encoding\n","from sklearn.preprocessing import LabelEncoder # para label encoding"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BTVLPtqFqPfr"},"source":["## Transformações Numéricas"]},{"cell_type":"markdown","metadata":{"id":"3PSf9bAxvJhR"},"source":["Muitos algoritmos de machine learning apresentam um melhor desempenho quando os atributos de entrada numéricos são redimensionados (exemplos: algoritmos que trabalham com a soma ponderada de entradas, como regressão linear, regressão logística e redes neurais; e algoritmos baseados em distância ou produto interno dos atributos de entrada, como o KNN e SVM).\n","\n","As duas técnicas mais populares para redimensionar dados numéricos antes da modelagem são **Normalização** e **Padronização**."]},{"cell_type":"code","metadata":{"id":"lHhKXN6dpKdW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667862273440,"user_tz":180,"elapsed":460,"user":{"displayName":"Tatiana Escovedo","userId":"12165060147632765890"}},"outputId":"d802197d-f575-4e5c-b12f-43ec5014a6b4"},"source":["# dados que iremos usar nos exemplos\n","data = pd.DataFrame([[100, 0.001],\n","\t\t\t\t[8, 0.05],\n","\t\t\t\t[50, 0.005],\n","\t\t\t\t[88, 0.07],\n","\t\t\t\t[4, 0.1]])\n","print(data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     0      1\n","0  100  0.001\n","1    8  0.050\n","2   50  0.005\n","3   88  0.070\n","4    4  0.100\n"]}]},{"cell_type":"markdown","metadata":{"id":"sZbuLX5Sp1pX"},"source":["### Normalização"]},{"cell_type":"markdown","metadata":{"id":"SBVVs-8vu8JC"},"source":["A Normalização redimensiona os dados do intervalo original para um novo intervalo entre 0 e 1. São utilizados os valores mínimo e máximo observáveis, sendo possível estimar esses valores a partir dos dados disponíveis.\n","\n","*y = (x – min) / (max – min)*\n","\n","Podemos normalizar os dados usando o objeto **MinMaxScaler**, do pacote **Scikit-learn**. A escala padrão é o intervalo [0,1], mas é possível especificar outro intervalo através do parâmetro *feature_range*, que será utilizado para todas as variáveis normalizadas.\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"]},{"cell_type":"code","metadata":{"id":"i7hGUQHIpWce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667862375339,"user_tz":180,"elapsed":234,"user":{"displayName":"Tatiana Escovedo","userId":"12165060147632765890"}},"outputId":"73f72cf7-450e-4cdb-e3c4-72d3f95171ce"},"source":["# definindo o transformador como min max scaler\n","scaler = MinMaxScaler()\n","\n","# transformando os dados\n","scaled = scaler.fit_transform(data)\n","print(scaled)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.         0.        ]\n"," [0.04166667 0.49494949]\n"," [0.47916667 0.04040404]\n"," [0.875      0.6969697 ]\n"," [0.         1.        ]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"meF1JOIaqRmO"},"source":["### Padronização"]},{"cell_type":"markdown","metadata":{"id":"nAx2IyEVvefx"},"source":["A Padronização redimensiona a distribuição dos valores observados para que a sua média seja 0 e o seu desvio padrão 1 (normal padrão).\n","\n","A padronização pressupõe que suas observações sigam uma distribuição Normal. Ainda é possível padronizar seus dados mesmo se essa premissa não for verdadeira, mas talvez os resultados sejam prejudicados.\n","\n","*y = (x - média) / desvio padrão*\n","\n","Podemos padronizar os dados usando o objeto **StandardScaler**, do pacote **Scikit-learn**.\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"]},{"cell_type":"code","metadata":{"id":"7CelMP4Npy4r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667862520491,"user_tz":180,"elapsed":235,"user":{"displayName":"Tatiana Escovedo","userId":"12165060147632765890"}},"outputId":"88cef66a-f52d-43ce-f150-70605d386fbc"},"source":["# definindo o transformador como standard scaler\n","scaler = StandardScaler()\n","\n","# transformando os dados\n","scaled = scaler.fit_transform(data)\n","print(scaled)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.26398112 -1.16389967]\n"," [-1.06174414  0.12639634]\n"," [ 0.         -1.05856939]\n"," [ 0.96062565  0.65304778]\n"," [-1.16286263  1.44302493]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"VhSyaQq6ygMe"},"source":["**Quando Normalizar e quando Padronizar?**\n","\n","* Se a distribuição é normal, padronize. Caso contrário, normalize.\n","* Os problemas de modelagem preditiva são muitas vezes complexos, não sendo clara a melhor transformação para realizar.\n","* Na dúvida, use a normalização. Se tiver tempo, explore os modelos com os dados sem transformação, com a padronização e com a normalização e veja se os resultados são significativamente diferentes e se o custo x benefício vale a pena."]},{"cell_type":"markdown","metadata":{"id":"iuj3mHe4qUPO"},"source":["## Transformações Categóricas"]},{"cell_type":"markdown","metadata":{"id":"uCPjwhG42FjU"},"source":["Algumas implementações de modelos de Machine Learning requerem que os atributos sejam numéricos, sendo necessário codificar os atributos categóricos em numéricos antes de treinar e utilizar o modelo.\n","\n","Usamos o **ordinal encoding** para as variáveis categóricas ordinais e o **one-hot encoding** para as variáveis categóricas nominais."]},{"cell_type":"code","metadata":{"id":"RKvm7cg6qa9g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667862727104,"user_tz":180,"elapsed":275,"user":{"displayName":"Tatiana Escovedo","userId":"12165060147632765890"}},"outputId":"24949d3e-58ca-40bd-95a9-ef14b5a84e3d"},"source":["# dados que iremos usar nos exemplos\n","data = np.asarray([['CMMIL2'], ['CMMIL3'], ['CMMIL4'], ['CMMIL3'], ['CMMIL4']])\n","print(data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['CMMIL2']\n"," ['CMMIL3']\n"," ['CMMIL4']\n"," ['CMMIL3']\n"," ['CMMIL4']]\n"]}]},{"cell_type":"markdown","metadata":{"id":"E47UeFzUrLqg"},"source":["### Ordinal Encoding"]},{"cell_type":"markdown","metadata":{"id":"-k05diRg2-ni"},"source":["No *ordinal encoding*, cada categoria única é transformada em um número inteiro, mantendo o relacionamento ordinal entre as variáveis. Este encoding não deve ser utilizado quando a variável não é ordinal, pois seria criada uma ordenação que não existe.\n","\n","O *ordinal encoding* é implementado pelo objeto **OrdinalEncoder**, do pacote **Scikit-learn**. Por padrão, serão atribuídos inteiros aos valores categóricos ordinais em ordem alfabética, mas é possível especificar a ordenação desejada através do parâmetro *categories*.\n","\n","A classe OrdinalEncoder é utilizada com atributos em formato matricial (organizadas em linhas e colunas). Se quisermos codificar uma variável target categórica, devemos usar a classe **LabelEncoder**, similar ao **OrdinalEncoder**, mas que espera um input de 1 dimensão apenas.\n","\n","http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gAhDed9T_l1t","executionInfo":{"status":"ok","timestamp":1667862804284,"user_tz":180,"elapsed":273,"user":{"displayName":"Tatiana Escovedo","userId":"12165060147632765890"}},"outputId":"7cb1fced-c373-4276-a16f-4f5ebca902e4"},"source":["# definindo o transformador como ordinal encoding\n","encoder = OrdinalEncoder()\n","\n","# transformando os dados\n","result = encoder.fit_transform(data)\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.]\n"," [1.]\n"," [2.]\n"," [1.]\n"," [2.]]\n"]}]},{"cell_type":"code","metadata":{"id":"qcxsG9YeqbDo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667862881268,"user_tz":180,"elapsed":331,"user":{"displayName":"Tatiana Escovedo","userId":"12165060147632765890"}},"outputId":"a2fd7edd-ff97-4f24-ef15-8e2dc4d96008"},"source":["target = np.asarray(['Sim', 'Não', 'Sim'])\n","\n","# definindo o transformador como label encoding\n","encoder = LabelEncoder()\n","\n","# transformando os dados\n","result = encoder.fit_transform(target)\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 1]\n"]}]},{"cell_type":"markdown","metadata":{"id":"TDfZ7IbPrOYN"},"source":["### One Hot Encoding"]},{"cell_type":"markdown","metadata":{"id":"FGLHFKo84_aF"},"source":["Para variáveis categóricas nominais, sem ordenação existente entre elas, devemos utilizar o *one-hot encoding*. Em vez de uma variável inteira, é criada uma variável binária para cada valor único da variável. Este nome se dá porque para cada possível categoria, apenas um bit é \"ativado\".\n","\n","O one-hot encoding é implementado pelo objeto **OneHotEncoder**, do pacote **Scikit-learn**, que ordena as categorias alfabeticamente antes de aplicar a transformação. É possível especificar a lista de categorias através do parâmetro *categories*.\n","\n","OBS: Espera-se que o conjunto de treinamento contenha pelo menos um exemplo de cada categoria se as categorias não forem explicitamente definidas. Se os novos dados (conjunto de teste, por exemplo) tiverem categorias não vistas no treinamento, é possível configurar o parâmetro \"handle_unknown\" como \"ignore\" para que não ocorra um erro.\n","\n","http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"]},{"cell_type":"code","metadata":{"id":"GRRAHCcxqzEN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667862932577,"user_tz":180,"elapsed":268,"user":{"displayName":"Tatiana Escovedo","userId":"12165060147632765890"}},"outputId":"9ed6e27d-61bf-44e7-a2bd-8c690dd51765"},"source":["# definindo o transformador como one hot encoding\n","encoder = OneHotEncoder(sparse=False)\n","\n","# transformando os dados\n","onehot = encoder.fit_transform(data)\n","print(onehot)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"-eDpdjYWrR0x"},"source":["### Dummy Variable Encoding"]},{"cell_type":"markdown","metadata":{"id":"K3f_usxt7O1z"},"source":["O one-hot encoding cria uma variável binária para cada categoria, mas esta representação inclui redundância. Por exemplo, se soubermos que [1, 0, 0] representa \"azul\" e [0, 1, 0] representa \"verde\", não precisamos de outra variável binária [0, 0, 1] para representar \"vermelho\". Poderíamos usar [0, 0] para \"vermelho\", [1, 0] para \"azul\" e [0, 1] para \"verde\". O *dummy encoding* representa C categorias em C-1 variáveis ​​binárias.\n","\n","A codificação dummy também é implementada pelo objeto **OneHotEncoder**, do pacote **Scikit-learn**, usando o parâmetro *drop* para indicar qual categoria receberá todos os valores zero, chamada de \"linha de base\". Podemos usar *first* para que a primeira categoria seja usada (as categorias são ordenadas alfabeticamente)."]},{"cell_type":"code","metadata":{"id":"6vA_bmO8q85I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667863108424,"user_tz":180,"elapsed":338,"user":{"displayName":"Tatiana Escovedo","userId":"12165060147632765890"}},"outputId":"975d698f-76db-4930-9b02-afb59f2c8563"},"source":["# definindo o transformador como one hot encoding (com Dummy variable encoder)\n","encoder = OneHotEncoder(drop='first', sparse=False)\n","\n","# transformando os dados\n","onehot = encoder.fit_transform(data)\n","print(onehot)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0. 0.]\n"," [1. 0.]\n"," [0. 1.]\n"," [1. 0.]\n"," [0. 1.]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"To9jCkxSFZ8v"},"source":["OBS: Se tivermos no mesmo dataset atributos dos dois tipos (numéricos e categóricos), será necessário transformar/codificar cada atributo (coluna) separadamente e concatenar todas as variáveis ​​preparadas novamente em uma única matriz para ajustar ou avaliar o modelo (ou usar o **ColumnTransformer** para aplicar condicionalmente diferentes transformações de dados a diferentes variáveis ​​de entrada).\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html"]},{"cell_type":"markdown","metadata":{"id":"vqIN4FR7iolQ"},"source":["## Exercícios"]},{"cell_type":"code","metadata":{"id":"ApT23HyVkDzV"},"source":["# configuração para não exibir os warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Importação de pacotes\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler # para normalização\n","from sklearn.preprocessing import StandardScaler # para padronização"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xknWmbkj-xN"},"source":["# Carrega arquivo csv usando Pandas usando uma URL\n","\n","# Informa a URL de importação do dataset\n","url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n","\n","# Informa o cabeçalho das colunas\n","colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n","\n","# Lê o arquivo utilizando as colunas informadas\n","dataset = pd.read_csv(url, names=colunas, skiprows=0, delimiter=',')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TcMT9DilkUww"},"source":["# Pegando apenas os dados do dataset e guardando em um array\n","array = dataset.values\n","\n","# Separando o array em componentes de input e output\n","X = array[:,0:8]\n","Y = array[:,8]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fwQNT5MPkVe1"},"source":["# 1. Normalize o dataset usando MinMaxScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sk9Pei18kbcy"},"source":["# 2. Padronize o dataset usando StandardScaler "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5TkjmDL0kwAi"},"source":["## Gabarito"]},{"cell_type":"code","metadata":{"id":"lBuTIcbGk1xS"},"source":["# 1. Normalize o dataset usando MinMaxScaler\n","\n","# Normalizando os dados\n","scaler = MinMaxScaler().fit(X)\n","normalizedX = scaler.transform(X)\n","\n","# Sumarizando os dados transformados\n","print(\"Dados Originais: \\n\\n\", X)\n","print(\"\\nDados Normalizados: \\n\\n\", normalizedX[0:5,:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTQhED9bk10M"},"source":["# 2. Padronize o dataset usando StandardScaler \n","\n","# Padronizando os dados\n","scaler = StandardScaler().fit(X)\n","standardX = scaler.transform(X)\n","\n","# Sumarizando os dados transformados\n","print(\"Dados Originais: \\n\\n\", X)\n","print(\"\\nDados Padronizados: \\n\\n\", standardX[0:5,:])"],"execution_count":null,"outputs":[]}]}